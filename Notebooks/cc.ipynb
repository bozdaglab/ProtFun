{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe31fd58-478a-4e0e-9df1-11699c732363",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CCO Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cba28d69-58ba-414f-88b0-5371c2e2524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "base_path = Path('path_to_data_directory')\n",
    "\n",
    "\n",
    "bp_train_path = base_path / 'bp/train_data.pkl'\n",
    "bp_valid_path = base_path / 'bp/valid_data.pkl'\n",
    "bp_test_path = base_path / 'bp/test_data.pkl'\n",
    "\n",
    "cc_train_path = base_path / 'cc/train_data.pkl'\n",
    "cc_valid_path = base_path / 'cc/valid_data.pkl'\n",
    "cc_test_path = base_path / 'cc/test_data.pkl'\n",
    "\n",
    "mf_train_path = base_path / 'mf/train_data.pkl'\n",
    "mf_valid_path = base_path / 'mf/valid_data.pkl'\n",
    "mf_test_path = base_path / 'mf/test_data.pkl'\n",
    "\n",
    "\n",
    "def preprocess(data_path, data_type, ont):\n",
    "    data = pd.read_pickle(data_path)\n",
    "    data.rename(columns={'prop_annotations': 'term'}, inplace=True)\n",
    "    data = data[['proteins', 'sequences', 'term']].rename(columns={'proteins': 'protein_name'})\n",
    "    data['Set'] = data_type\n",
    "    data['aspect'] = ont\n",
    "    return data\n",
    "\n",
    "\n",
    "bp_train = preprocess(bp_train_path, \"Train\", \"BPO\")\n",
    "cc_train = preprocess(cc_train_path, \"Train\", \"CCO\")\n",
    "mf_train = preprocess(mf_train_path, \"Train\", \"MFO\")\n",
    "\n",
    "bp_valid = preprocess(bp_valid_path, \"Valid\", \"BPO\")\n",
    "cc_valid = preprocess(cc_valid_path, \"Valid\", \"CCO\")\n",
    "mf_valid = preprocess(mf_valid_path, \"Valid\", \"MFO\")\n",
    "\n",
    "bp_test = preprocess(bp_test_path, \"Test\", \"BPO\")\n",
    "cc_test = preprocess(cc_test_path, \"Test\", \"CCO\")\n",
    "mf_test = preprocess(mf_test_path, \"Test\", \"MFO\")\n",
    "\n",
    "# Concatenate \n",
    "mf = pd.concat([mf_train, mf_valid, mf_test], ignore_index=True)\n",
    "cc = pd.concat([cc_train, cc_valid, cc_test], ignore_index=True)\n",
    "bp = pd.concat([bp_train, bp_valid, bp_test], ignore_index=True)\n",
    "\n",
    "data = pd.concat([bp, cc, mf], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa882bbd-77fc-4bd4-948c-d94fbba0ba36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_name</th>\n",
       "      <th>sequences</th>\n",
       "      <th>term</th>\n",
       "      <th>Set</th>\n",
       "      <th>aspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VNX1_YEAST</td>\n",
       "      <td>MAKNNHISASGNSTSGDHRLKEEVLTPTTSASTPHRIFSVDDDPKE...</td>\n",
       "      <td>[GO:0005783, GO:0051234, GO:1902600, GO:000032...</td>\n",
       "      <td>Train</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PP202_ARATH</td>\n",
       "      <td>MLVFKSTMECSISSTIHVLGSCKTSDDVNQIHGRLIKTGIIKNSNL...</td>\n",
       "      <td>[GO:0043170, GO:0034641, GO:0043231, GO:001607...</td>\n",
       "      <td>Train</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y1829_MYCTU</td>\n",
       "      <td>MGEVRVVGIRVEQPQNQPVLLLREANGDRYLPIWIGQSEAAAIALE...</td>\n",
       "      <td>[GO:0110165, GO:0005886, GO:0030312, GO:000561...</td>\n",
       "      <td>Train</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCRB1_RAT</td>\n",
       "      <td>MGVSSRARWVALGLGVLGLLCAALGVIMILMVPSLIKQQVLKNVRI...</td>\n",
       "      <td>[GO:0038024, GO:0015629, GO:0099080, GO:000998...</td>\n",
       "      <td>Train</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCRB1_MOUSE</td>\n",
       "      <td>MGGSSRARWVALGLGALGLLFAALGVVMILMVPSLIKQQVLKNVRI...</td>\n",
       "      <td>[GO:0009395, GO:0042592, GO:0008283, GO:005089...</td>\n",
       "      <td>Train</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  protein_name                                          sequences  \\\n",
       "0   VNX1_YEAST  MAKNNHISASGNSTSGDHRLKEEVLTPTTSASTPHRIFSVDDDPKE...   \n",
       "1  PP202_ARATH  MLVFKSTMECSISSTIHVLGSCKTSDDVNQIHGRLIKTGIIKNSNL...   \n",
       "2  Y1829_MYCTU  MGEVRVVGIRVEQPQNQPVLLLREANGDRYLPIWIGQSEAAAIALE...   \n",
       "3    SCRB1_RAT  MGVSSRARWVALGLGVLGLLCAALGVIMILMVPSLIKQQVLKNVRI...   \n",
       "4  SCRB1_MOUSE  MGGSSRARWVALGLGALGLLFAALGVVMILMVPSLIKQQVLKNVRI...   \n",
       "\n",
       "                                                term    Set aspect  \n",
       "0  [GO:0005783, GO:0051234, GO:1902600, GO:000032...  Train    CCO  \n",
       "1  [GO:0043170, GO:0034641, GO:0043231, GO:001607...  Train    CCO  \n",
       "2  [GO:0110165, GO:0005886, GO:0030312, GO:000561...  Train    CCO  \n",
       "3  [GO:0038024, GO:0015629, GO:0099080, GO:000998...  Train    CCO  \n",
       "4  [GO:0009395, GO:0042592, GO:0008283, GO:005089...  Train    CCO  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84766899-e13b-45e8-afa3-5b45c332f5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_name</th>\n",
       "      <th>sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VNX1_YEAST</td>\n",
       "      <td>MAKNNHISASGNSTSGDHRLKEEVLTPTTSASTPHRIFSVDDDPKE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PP202_ARATH</td>\n",
       "      <td>MLVFKSTMECSISSTIHVLGSCKTSDDVNQIHGRLIKTGIIKNSNL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y1829_MYCTU</td>\n",
       "      <td>MGEVRVVGIRVEQPQNQPVLLLREANGDRYLPIWIGQSEAAAIALE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCRB1_RAT</td>\n",
       "      <td>MGVSSRARWVALGLGVLGLLCAALGVIMILMVPSLIKQQVLKNVRI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCRB1_MOUSE</td>\n",
       "      <td>MGGSSRARWVALGLGALGLLFAALGVVMILMVPSLIKQQVLKNVRI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  protein_name                                          sequences\n",
       "0   VNX1_YEAST  MAKNNHISASGNSTSGDHRLKEEVLTPTTSASTPHRIFSVDDDPKE...\n",
       "1  PP202_ARATH  MLVFKSTMECSISSTIHVLGSCKTSDDVNQIHGRLIKTGIIKNSNL...\n",
       "2  Y1829_MYCTU  MGEVRVVGIRVEQPQNQPVLLLREANGDRYLPIWIGQSEAAAIALE...\n",
       "3    SCRB1_RAT  MGVSSRARWVALGLGVLGLLCAALGVIMILMVPSLIKQQVLKNVRI...\n",
       "4  SCRB1_MOUSE  MGGSSRARWVALGLGALGLLFAALGVVMILMVPSLIKQQVLKNVRI..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seq = cc[['protein_name', 'sequences']].drop_duplicates().reset_index(drop = True)\n",
    "df_seq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac35332d-9988-49bb-b47c-6866a9b02bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_name</th>\n",
       "      <th>sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59257</td>\n",
       "      <td>59257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>59257</td>\n",
       "      <td>58364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>VNX1_YEAST</td>\n",
       "      <td>MADQLTEEQIAEFKEAFSLFDKDGDGTITTKELGTVMRSLGQNPTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       protein_name                                          sequences\n",
       "count         59257                                              59257\n",
       "unique        59257                                              58364\n",
       "top      VNX1_YEAST  MADQLTEEQIAEFKEAFSLFDKDGDGTITTKELGTVMRSLGQNPTE...\n",
       "freq              1                                                 11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seq.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546c861e-873c-4fae-a9a0-15a05992bfb2",
   "metadata": {},
   "source": [
    "# GO Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30fc557f-9b40-4e73-8574-5aa4996e5c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_name</th>\n",
       "      <th>term</th>\n",
       "      <th>Set</th>\n",
       "      <th>aspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VNX1_YEAST</td>\n",
       "      <td>GO:0005783</td>\n",
       "      <td>Train</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VNX1_YEAST</td>\n",
       "      <td>GO:0051234</td>\n",
       "      <td>Train</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VNX1_YEAST</td>\n",
       "      <td>GO:1902600</td>\n",
       "      <td>Train</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VNX1_YEAST</td>\n",
       "      <td>GO:0000323</td>\n",
       "      <td>Train</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VNX1_YEAST</td>\n",
       "      <td>GO:0015075</td>\n",
       "      <td>Train</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  protein_name        term    Set aspect\n",
       "0   VNX1_YEAST  GO:0005783  Train    CCO\n",
       "1   VNX1_YEAST  GO:0051234  Train    CCO\n",
       "2   VNX1_YEAST  GO:1902600  Train    CCO\n",
       "3   VNX1_YEAST  GO:0000323  Train    CCO\n",
       "4   VNX1_YEAST  GO:0015075  Train    CCO"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = cc[['protein_name', 'term', 'Set', 'aspect']]\n",
    "go_terms = terms.explode('term').reset_index(drop=True)\n",
    "go_terms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe80522-7ff7-46a0-8b5a-e9f7eae4a977",
   "metadata": {},
   "source": [
    "## LLM EMBEDDINGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14307dd0-d563-4b8f-81c5-75d173f8d1ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_name</th>\n",
       "      <th>ANKH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VGFR2_MOUSE</td>\n",
       "      <td>[[0.02048352360725403, 0.0012277299538254738, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VGFR2_RAT</td>\n",
       "      <td>[[0.020595740526914597, 0.0011519812978804111,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VGFR2_HUMAN</td>\n",
       "      <td>[[0.020025640726089478, 0.001570425578393042, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VGFR2_DANRE</td>\n",
       "      <td>[[0.02045329473912716, 0.0011346322717145085, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KIT_MOUSE</td>\n",
       "      <td>[[0.01818038336932659, 0.0016508179251104593, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  protein_name                                               ANKH\n",
       "0  VGFR2_MOUSE  [[0.02048352360725403, 0.0012277299538254738, ...\n",
       "1    VGFR2_RAT  [[0.020595740526914597, 0.0011519812978804111,...\n",
       "2  VGFR2_HUMAN  [[0.020025640726089478, 0.001570425578393042, ...\n",
       "3  VGFR2_DANRE  [[0.02045329473912716, 0.0011346322717145085, ...\n",
       "4    KIT_MOUSE  [[0.01818038336932659, 0.0016508179251104593, ..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### LLM ####\n",
    "ankh_embeds_array = np.load(\"path_to_directory/ankh_embeddings_zerogo_embeds.npy\")\n",
    "ankh_ids_array = np.load(\"path_to_directory/ankh_embeddings_zerogo_ids.npy\")\n",
    "ankh = pd.DataFrame({'protein_name': ankh_ids_array, 'ANKH': ankh_embeds_array.tolist()})\n",
    "ankh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b033bd47-6993-4335-9464-55b24dafb801",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac2f3b13-cf00-4fb1-82a9-2dbca537625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology = 'CCO'\n",
    "task_name = 'zerogo/cc' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "991557bb-9817-4ed3-a6ae-ccb2e5d277e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths(task_name):\n",
    "    base_dir = 'define_directory'\n",
    "    \n",
    "    valid_pred_folder = os.path.join(base_dir, f'predictions/{task_name}/Valid')\n",
    "    test_pred_folder = os.path.join(base_dir, f'predictions/{task_name}/Test')\n",
    "    obo_file = os.path.join(base_dir, 'metrics/go-basic.obo')\n",
    "    valid_gt = os.path.join(base_dir, f'metrics/gt/{task_name}/valid.tsv')\n",
    "    test_gt = os.path.join(base_dir, f'metrics/gt/{task_name}/test.tsv')\n",
    "    model_dir = os.path.join(base_dir, f'models/{task_name}')\n",
    "    valid_preds = os.path.join(base_dir, f'predictions/{task_name}/Valid/valid_pred.tsv')\n",
    "    test_preds = os.path.join(base_dir, f'predictions/{task_name}/Test/test_pred.tsv')\n",
    "    result_df = os.path.join(base_dir, f'results/{task_name}/evaluation_all.tsv')\n",
    "    result_folder = os.path.join(base_dir, f'results/{task_name}')\n",
    "    \n",
    "    return (valid_pred_folder, test_pred_folder, obo_file, valid_gt, test_gt, model_dir, valid_preds, test_preds, result_df, result_folder)\n",
    "\n",
    "\n",
    "(valid_pred_folder, test_pred_folder, obo_file, valid_gt, test_gt, model_dir, valid_preds, test_preds, result_df, result_folder) = paths(task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "800dd496-623b-4a25-a801-6301d986ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "go_df = pd.read_pickle('/data/cc/terms.pkl')\n",
    "\n",
    "def valid_and_test_gt(go_terms, ontology, valid_gt, test_gt):\n",
    "\n",
    "    goes = go_terms[(go_terms['aspect'] == ontology)]\n",
    "    task =goes[goes['term'].isin(go_df['gos'])]\n",
    "    task = task.drop_duplicates().reset_index(drop=True)\n",
    "    set_df = task[['protein_name', 'Set']]\n",
    "    set_df = set_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "  \n",
    "    valid = task[(task['aspect'] == ontology) & (task['Set'] == 'Valid')]\n",
    "    valid = valid[['protein_name', 'term']]\n",
    "    valid = valid.rename(columns={'protein_name': 'EntryID'})\n",
    "    valid = valid.reset_index(drop=True)\n",
    "    valid.to_csv(valid_gt, sep='\\t', index=False, header=True)\n",
    "\n",
    "    test = task[(task['aspect'] == ontology) & (task['Set'] == 'Test')]\n",
    "    test = test[['protein_name', 'term']]\n",
    "    test = test.rename(columns={'protein_name': 'EntryID'})\n",
    "    test = test.reset_index(drop=True)\n",
    "    test.to_csv(test_gt, sep='\\t', index=False, header=True)\n",
    "    return task, set_df\n",
    "\n",
    "task, set_df = valid_and_test_gt(go_terms, ontology, valid_gt, test_gt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd312dc-94eb-42d0-a8f4-7399c3a463db",
   "metadata": {},
   "source": [
    "# Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88be255c-0eee-446e-9dba-8ee98598f93e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ordered_labels = task.groupby('term')['protein_name'].count().sort_values(ascending=False)\n",
    "labels =ordered_labels[ordered_labels>=10]\n",
    "labels_names = labels.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f95dbeb5-60f9-4a59-b50d-20e006a95bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1338"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a50b8d8-0d90-4f2f-8822-bbd315ccf6a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59257it [00:12, 4837.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_name</th>\n",
       "      <th>labels_vect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VNX1_YEAST</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PP202_ARATH</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y1829_MYCTU</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCRB1_RAT</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCRB1_MOUSE</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  protein_name                                        labels_vect\n",
       "0   VNX1_YEAST  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
       "1  PP202_ARATH  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, ...\n",
       "2  Y1829_MYCTU  [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...\n",
       "3    SCRB1_RAT  [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, ...\n",
       "4  SCRB1_MOUSE  [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, ..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_labels = task.groupby('protein_name')['term'].apply(list).to_dict()\n",
    "ids = np.array(task['protein_name'].unique())\n",
    "\n",
    "go_terms_map = {label: i for i, label in enumerate(labels_names)}\n",
    "labels_matrix = np.zeros((len(ids), len(labels_names)))\n",
    "\n",
    "from tqdm import tqdm\n",
    "for index, id in tqdm(enumerate(ids)):\n",
    "    id_gos_list = id_labels[id]\n",
    "    temp = [go_terms_map[go] for go in labels_names if go in id_gos_list]\n",
    "    labels_matrix[index, temp] = 1\n",
    "\n",
    "labels_list = []\n",
    "for l in range(labels_matrix.shape[0]):\n",
    "    labels_list.append(labels_matrix[l, :])\n",
    "\n",
    "labels_df = pd.DataFrame(data={\"protein_name\":ids, \"labels_vect\":labels_list})\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2220743c-43bd-4c86-acdd-5c691b03577e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59257, 1338)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c98e1f-3c27-4f2c-a435-153fa327a89d",
   "metadata": {},
   "source": [
    "# Interproscan embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e999c0e0-ecc3-4b9c-8bd5-103b40ccc50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpro = pd.read_pickle('path_to_directory/binary_zerogo.pkl')\n",
    "pro_proteins = labels_df[['protein_name']]\n",
    "\n",
    "binary = pd.merge(pro_proteins, interpro, on='protein_name', how='left')\n",
    "vector_length = len(interpro['binary_vector'][0])\n",
    "binary['binary_vector'] = binary['binary_vector'].apply(lambda x: x if isinstance(x, list) else [0] * vector_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd55a6f-c5ac-4398-9631-593a5bda9ed9",
   "metadata": {},
   "source": [
    "# Merge ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6bdff72d-8725-4316-8dfc-6385a4944562",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(ankh, labels_df, on='protein_name')\n",
    "merged_df = pd.merge(merged_df, binary, on='protein_name')\n",
    "final_df = pd.merge(merged_df, set_df, on='protein_name')\n",
    "final_df.drop_duplicates(subset=['protein_name'], inplace=True)\n",
    "final_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f54144fe-7500-46d8-8e9b-468187a6ead7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_name</th>\n",
       "      <th>ANKH</th>\n",
       "      <th>labels_vect</th>\n",
       "      <th>binary_vector</th>\n",
       "      <th>Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VGFR2_MOUSE</td>\n",
       "      <td>[[0.02048352360725403, 0.0012277299538254738, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VGFR2_RAT</td>\n",
       "      <td>[[0.020595740526914597, 0.0011519812978804111,...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VGFR2_HUMAN</td>\n",
       "      <td>[[0.020025640726089478, 0.001570425578393042, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KIT_MOUSE</td>\n",
       "      <td>[[0.01818038336932659, 0.0016508179251104593, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KIT_HUMAN</td>\n",
       "      <td>[[0.018293721601366997, 0.001633501029573381, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  protein_name                                               ANKH  \\\n",
       "0  VGFR2_MOUSE  [[0.02048352360725403, 0.0012277299538254738, ...   \n",
       "1    VGFR2_RAT  [[0.020595740526914597, 0.0011519812978804111,...   \n",
       "2  VGFR2_HUMAN  [[0.020025640726089478, 0.001570425578393042, ...   \n",
       "3    KIT_MOUSE  [[0.01818038336932659, 0.0016508179251104593, ...   \n",
       "4    KIT_HUMAN  [[0.018293721601366997, 0.001633501029573381, ...   \n",
       "\n",
       "                                         labels_vect  \\\n",
       "0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "1  [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, ...   \n",
       "2  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "3  [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n",
       "4  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...   \n",
       "\n",
       "                                       binary_vector    Set  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  Train  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  Train  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  Train  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  Train  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  Train  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e47f04e-96b6-45e7-8963-929d261e3d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first protein belongs to 3 families.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The first protein belongs to {sum(final_df['binary_vector'][0])} families.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be36a1-1150-4a83-870d-2ffccdbf8fad",
   "metadata": {},
   "source": [
    "# Protein Family Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f07353e2-306b-4745-a5df-6fc25a14a2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfam = pd.read_pickle('path_to_directory/zerogo_network.pkl')\n",
    "network = pfam[pfam['protein1'].isin(final_df['protein_name']) & pfam['protein2'].isin(final_df['protein_name'])]\n",
    "\n",
    "network.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c363856-95c7-40f6-90e0-6505beb0ad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "protein_names = final_df['protein_name'].tolist()\n",
    "protein_to_index = {protein: index for index, protein in enumerate(protein_names)}\n",
    "\n",
    "interpro = torch.tensor(np.array(final_df['binary_vector'].tolist()), dtype=torch.float64).squeeze().contiguous()\n",
    "ankh = torch.tensor(np.array(final_df['ANKH'].tolist()), dtype=torch.float64).squeeze().contiguous()\n",
    "labels = torch.tensor(np.array(final_df['labels_vect'].tolist()), dtype=torch.float64)\n",
    "\n",
    "\n",
    "train_mask = torch.tensor(final_df['Set'] == 'Train', dtype=torch.bool) \n",
    "valid_mask = torch.tensor(final_df['Set'] == 'Valid', dtype=torch.bool) \n",
    "test_mask = torch.tensor(final_df['Set'] == 'Test', dtype=torch.bool) \n",
    "\n",
    "\n",
    "\n",
    "edges = [(protein_to_index[row['protein1']], protein_to_index[row['protein2']]) for _, row in network.iterrows()]\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t()\n",
    "\n",
    "\n",
    "data = Data(edge_index=edge_index,  x=interpro, ankh =ankh,  y = labels,  train_mask = train_mask, valid_mask = valid_mask, test_mask = test_mask )\n",
    "data.is_undirected();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac415e1f-c420-48f6-a735-752354d7200f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[59257, 10879], edge_index=[2, 4649485], y=[59257, 1338], ankh=[59257, 1536], train_mask=[59257], valid_mask=[59257], test_mask=[59257])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5c699b3-b6b1-43a6-af90-ce66cd3f1110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 59257\n",
      "Number of node features: 10879\n",
      "Number of edges: 4649485\n",
      "Average node degree: 78.46\n",
      "Number of training nodes: 48318\n",
      "Number of validation nodes: 4970\n",
      "Number of test nodes: 5969\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of node features: {data.num_node_features}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Number of validation nodes: {data.valid_mask.sum()}')\n",
    "print(f'Number of test nodes: {data.test_mask.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a58c802-105f-4713-9885-4dc10d5bbf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
    "from torch_geometric.utils import dropout_edge\n",
    "from torch import nn\n",
    "\n",
    "num_classes = len(labels_names)\n",
    "family_features = data.x.size(1)\n",
    "ankh_features = data.ankh.size(1)\n",
    "\n",
    "\n",
    "class PLLM(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim):\n",
    "        super(PLLM, self).__init__()\n",
    "        torch.manual_seed(1234)\n",
    "        self.linear1 = torch.nn.Linear(input_dim, 2048)\n",
    "        self.activation1 = nn.LeakyReLU(0.1)\n",
    "        self.linear2 = torch.nn.Linear(2048, 1024)\n",
    "        self.activation2 = nn.LeakyReLU(0.1)\n",
    "        self.linear3 = torch.nn.Linear(1024, 512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.linear2(x)  \n",
    "        x = self.activation2(x)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "  \n",
    "\n",
    "class GATN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_heads):\n",
    "        super(GATN, self).__init__()\n",
    "        torch.manual_seed(1234)\n",
    "        self.gat1 = GATConv(in_channels=input_dim,\n",
    "                            out_channels=hidden_dim,\n",
    "                            heads=num_heads,\n",
    "                            concat=True,\n",
    "                            add_self_loops=True,\n",
    "                            bias=True)\n",
    "        self.gat2 = GATConv(in_channels=hidden_dim * num_heads,\n",
    "                            out_channels=512,\n",
    "                            heads=1,\n",
    "                            concat=True,\n",
    "                            add_self_loops=True,\n",
    "                            bias=True)  \n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gat1(x, edge_index)  \n",
    "        x = F.relu(x)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Voltron(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Voltron, self).__init__()\n",
    "        torch.manual_seed(1234)\n",
    "        self.lin1 = torch.nn.Linear(1024, 512)  \n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.act1 = nn.LeakyReLU(0.1)\n",
    "        self.lin2 = torch.nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, mlp_output, gat_output):\n",
    "        x = torch.cat((mlp_output, gat_output), dim=1)  \n",
    "        x = self.lin1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        out = self.lin2(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3caa1fce-127d-4493-b704-9f06f8e978f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborLoader\n",
    "data.x = data.x.contiguous()\n",
    "data.ankh = data.ankh.contiguous()\n",
    "data.edge_index = data.edge_index.contiguous()\n",
    "\n",
    "train_loader = NeighborLoader(data, input_nodes=data.train_mask,\n",
    "                              num_neighbors=[75, 30], batch_size= 128, shuffle=True)\n",
    "\n",
    "val_loader   = NeighborLoader(data, input_nodes=data.valid_mask,\n",
    "                              num_neighbors=[75, 30], batch_size=1, shuffle=False)\n",
    "\n",
    "test_loader  = NeighborLoader(data, input_nodes=data.test_mask,\n",
    "                              num_neighbors=[75, 30], batch_size=1,  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e42e9285-d2bb-4bf7-81be-c9dd5a8c3114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cafaeval\n",
    "from cafaeval.evaluation import cafa_eval, write_results\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4499bf5e-1068-4773-87a6-f1d870458e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will start on cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import  Data\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import cafaeval\n",
    "from cafaeval.evaluation import cafa_eval, write_results\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Training will start on {device}')\n",
    "\n",
    "train_loss_history=[]\n",
    "val_loss_history=[]\n",
    "val_fmax_history = []\n",
    "\n",
    "def train(train_loader, val_loader, out_dir, num_epochs):\n",
    "  \n",
    "    mlp_model = PLLM(input_dim=family_features).to(device)\n",
    "    gat_model = GATN(input_dim=ankh_features, hidden_dim = 256, num_heads=3).to(device)\n",
    "    model = Voltron(num_classes = num_classes).to(device)\n",
    "    \n",
    "    mlp_model = mlp_model.double()\n",
    "    gat_model = gat_model.double() \n",
    "    model = model.double()\n",
    "\n",
    "    params = list(mlp_model.parameters()) + list(gat_model.parameters()) + list(model.parameters())\n",
    "    optimizer = torch.optim.Adam(params, lr = 0.0001)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    \n",
    "\n",
    "    patience_counter = 0\n",
    "    best_fmax = 0.0\n",
    "    best_val_loss = float('inf')\n",
    "    best_s_min =  float('inf')\n",
    "    \n",
    "    ## TRAIN     \n",
    "    for epoch in range(num_epochs):\n",
    "       \n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            mlp_model.train()\n",
    "            gat_model.train()\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            batch = batch.to(device)\n",
    "            #model outputs\n",
    "            mlp_out = mlp_model(batch.x)\n",
    "            mlp_out = mlp_out[:batch.batch_size]\n",
    "            gat_out = gat_model(batch.ankh, batch.edge_index)\n",
    "            gat_out = gat_out[:batch.batch_size]\n",
    "            out = model(mlp_out, gat_out)\n",
    "            out = out[:batch.batch_size]\n",
    "           \n",
    "            y = batch.y[:batch.batch_size].double()\n",
    "            \n",
    "            \n",
    "            loss = criterion(out, y)\n",
    "        \n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward() \n",
    "            optimizer.step()  \n",
    "\n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "        train_loss_history.append(avg_train_loss)\n",
    "\n",
    "        ## Evaluation on validation Set \n",
    "        val_losses = []\n",
    "        val_scores = [] \n",
    "        s_min_values = []\n",
    "        \n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            names = np.empty(shape=(len(val_loader)*num_classes,), dtype=object)\n",
    "            go = np.empty(shape=(len(val_loader)*num_classes,), dtype=object)\n",
    "            confidence = np.empty(shape=(len(val_loader)*num_classes,), dtype=np.float64)\n",
    "            val_protein_names = final_df[final_df['Set'] == 'Valid']['protein_name']\n",
    "            \n",
    "            for i, (batch, p_name) in enumerate(zip(val_loader, val_protein_names)):\n",
    "                batch = batch.to(device)\n",
    "                \n",
    "                #Models' predictions on Validation Set\n",
    "                mlp_out = mlp_model(batch.x)\n",
    "                mlp_out = mlp_out[:batch.batch_size]\n",
    "                gat_out = gat_model(batch.ankh, batch.edge_index)\n",
    "                gat_out = gat_out[:batch.batch_size]\n",
    "                out = model(mlp_out, gat_out)\n",
    "                out = out[:batch.batch_size]\n",
    "\n",
    "                y = batch.y[:batch.batch_size].double()\n",
    "                \n",
    "                #Validation loss\n",
    "                val_loss = criterion(out, y)\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "               \n",
    "                confidence[i*num_classes:(i+1)*num_classes] = torch.sigmoid(out).squeeze().detach().cpu().numpy()\n",
    "                names[i*num_classes:(i+1)*num_classes] = p_name  \n",
    "                go[i*num_classes:(i+1)*num_classes] = labels_names\n",
    "                \n",
    "            submission = pd.DataFrame(data={\"Protein_name\": names, \"GO term\": go, \"Confidence\": confidence})\n",
    "            submission_df = submission[submission['Confidence'] >= 0.01]\n",
    "            with open(valid_preds, 'w') as file:\n",
    "                submission_df.to_csv(file, sep='\\t', index=False, header=False)\n",
    "                \n",
    "            df, df_best =cafa_eval(obo_file, valid_pred_folder, valid_gt)\n",
    "            f_max = df_best['f'].loc['valid_pred.tsv'].xs('cellular_component', level='ns')['f'].iloc[0]\n",
    "            s_min = df_best['f'].loc['valid_pred.tsv'].xs('cellular_component', level='ns')['s'].iloc[0]\n",
    "            \n",
    "            s_min_values.append(s_min.item())\n",
    "            val_scores.append(f_max.item())\n",
    "            val_loss_values = np.mean(val_losses)\n",
    "            avg_s_min = np.mean(s_min_values)\n",
    "            \n",
    "            \n",
    "        avg_fmax  = np.mean(val_scores)\n",
    "        avg_s_min = np.mean(s_min_values)\n",
    "        avg_val_loss = np.mean(val_loss_values)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        val_loss_history.append(val_loss_values)\n",
    "        val_fmax_history.append(avg_fmax)\n",
    "\n",
    "        \n",
    "        \n",
    "        if avg_fmax >= best_fmax:\n",
    "            best_fmax = max(avg_fmax, best_fmax)\n",
    "            \n",
    "            mlp_path = os.path.join(out_dir, f'cc_mlp_model.pt')\n",
    "            gat_path = os.path.join(out_dir, f'cc_gat_model.pt')\n",
    "            voltron_path = os.path.join(out_dir, f'cc_voltron_model.pt')\n",
    "                \n",
    "            torch.save(mlp_model.state_dict(), mlp_path)\n",
    "            torch.save(gat_model.state_dict(), gat_path)\n",
    "            torch.save(model.state_dict(), voltron_path)\n",
    "            \n",
    "        if  (avg_s_min < best_s_min) or (avg_val_loss < best_val_loss): \n",
    "            best_val_loss = min(avg_val_loss, best_val_loss)\n",
    "            best_s_min = min(avg_s_min, best_s_min)\n",
    "            patience_counter = 0   \n",
    "    \n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter == 5:\n",
    "            print('=' * 100)\n",
    "            print('EARLY STOPPING ACTIVATED')\n",
    "            break\n",
    "\n",
    "        print(f'EPOCH: {epoch + 1:03d} | S_min:{avg_s_min: .5f} | F_max:{avg_fmax : .3f}')\n",
    "\n",
    "\n",
    "\n",
    "    return model              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7f08a009-24be-431d-88b9-af3e42e84fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 001 | S_min: 8.17169 | F_max: 0.646\n",
      "EPOCH: 002 | S_min: 8.05841 | F_max: 0.653\n",
      "EPOCH: 003 | S_min: 7.90865 | F_max: 0.666\n",
      "EPOCH: 004 | S_min: 7.55390 | F_max: 0.679\n",
      "EPOCH: 005 | S_min: 7.42105 | F_max: 0.689\n",
      "EPOCH: 006 | S_min: 7.31439 | F_max: 0.694\n",
      "EPOCH: 007 | S_min: 7.31995 | F_max: 0.696\n",
      "EPOCH: 008 | S_min: 7.24363 | F_max: 0.698\n",
      "EPOCH: 009 | S_min: 7.28159 | F_max: 0.699\n",
      "EPOCH: 010 | S_min: 7.16631 | F_max: 0.704\n",
      "EPOCH: 011 | S_min: 7.12240 | F_max: 0.704\n",
      "EPOCH: 012 | S_min: 7.10188 | F_max: 0.704\n",
      "EPOCH: 013 | S_min: 7.17611 | F_max: 0.702\n",
      "EPOCH: 014 | S_min: 7.19298 | F_max: 0.700\n",
      "EPOCH: 015 | S_min: 7.11095 | F_max: 0.704\n",
      "EPOCH: 016 | S_min: 7.15131 | F_max: 0.703\n",
      "EPOCH: 017 | S_min: 7.15344 | F_max: 0.704\n",
      "====================================================================================================\n",
      "EARLY STOPPING ACTIVATED\n"
     ]
    }
   ],
   "source": [
    "model = train(train_loader = train_loader, val_loader = val_loader, out_dir = model_dir, num_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2138071-ec75-40c6-a41d-e8f89b928f8f",
   "metadata": {},
   "source": [
    "# TEST TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "948866b3-99a0-4a55-b736-ee1f7b2de7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5969it [01:05, 91.03it/s] \n"
     ]
    }
   ],
   "source": [
    "#Load the saved models\n",
    "\n",
    "mlp_path = os.path.join(model_dir, f'cc_mlp_model.pt')\n",
    "gat_path = os.path.join(model_dir, f'cc_gat_model.pt')\n",
    "voltron_path = os.path.join(model_dir, f'cc_voltron_model.pt')\n",
    "\n",
    "mlp_model = PLLM(input_dim=family_features).to(device)\n",
    "mlp_model = mlp_model.double()\n",
    "gat_model = GATN(input_dim=ankh_features, hidden_dim = 256, num_heads=3).to(device)\n",
    "\n",
    "\n",
    "gat_model = gat_model.double()\n",
    "model = Voltron(num_classes = num_classes).to(device)\n",
    "model = model.double()\n",
    "\n",
    "mlp_model.load_state_dict(torch.load(mlp_path))\n",
    "gat_model.load_state_dict(torch.load(gat_path))\n",
    "model.load_state_dict(torch.load(voltron_path))\n",
    "\n",
    "# Evaluate on TEST SET \n",
    "model.eval()\n",
    "names = np.empty(shape=(len(test_loader)*num_classes,), dtype=object)\n",
    "go = np.empty(shape=(len(test_loader)*num_classes,), dtype=object)\n",
    "confidence = np.empty(shape=(len(test_loader)*num_classes,), dtype=np.float64)\n",
    "test_protein_names = final_df[final_df['Set'] == 'Test']['protein_name']\n",
    "\n",
    "for i, (batch, p_name) in tqdm(enumerate(zip(test_loader, test_protein_names))):\n",
    "    batch = batch.to(device)\n",
    "    \n",
    "    mlp_out = mlp_model(batch.x)\n",
    "    mlp_out = mlp_out[:batch.batch_size]\n",
    "    gat_out = gat_model(batch.ankh, batch.edge_index)\n",
    "    gat_out = gat_out[:batch.batch_size]\n",
    "    out = model(mlp_out, gat_out)\n",
    "    out = out[:batch.batch_size]\n",
    "    \n",
    "    confidence[i*num_classes:(i+1)*num_classes] = torch.sigmoid(out).squeeze().detach().cpu().numpy()\n",
    "    names[i*num_classes:(i+1)*num_classes] = p_name  # Assign p_name from test_protein_names\n",
    "    go[i*num_classes:(i+1)*num_classes] = labels_names\n",
    "\n",
    "\n",
    "testing = pd.DataFrame(data={\"protein_name\": names, \"GO term\": go, \"Confidence\": confidence})\n",
    "submission_df = testing.copy()\n",
    "submission_df = testing[testing['Confidence'] >= 0.01]\n",
    "with open(test_preds, 'w') as file:\n",
    "    submission_df.to_csv(test_preds, sep='\\t', index=False, header=False)\n",
    "df, df_b =cafa_eval(obo_file, test_pred_folder, test_gt)\n",
    "test_f_max = df_b['f'].loc['test_pred.tsv'].xs('cellular_component', level='ns')['f'].iloc[0]\n",
    "smin = df_b['f'].xs('cellular_component', level='ns')['s'].iloc[0]\n",
    "\n",
    "precisions = df.xs('cellular_component', level='ns').loc['test_pred.tsv']['pr'].to_numpy()\n",
    "recalls = df.xs('cellular_component', level='ns').loc['test_pred.tsv']['rc'].to_numpy()\n",
    "sorted_index = np.argsort(recalls)\n",
    "recalls = recalls[sorted_index]\n",
    "precisions = precisions[sorted_index]\n",
    "aupr = np.trapz(precisions, recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4d686909-9afd-46c4-9825-cd057ead551d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fmax: 0.710\n",
      "Smin: 6.796\n",
      "AUPR: 0.597\n"
     ]
    }
   ],
   "source": [
    "print(f'Fmax: {test_f_max:0.3f}')\n",
    "print(f'Smin: {smin :0.3f}')\n",
    "print(f'AUPR: {aupr:0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f316cf-3dba-44aa-b24e-860ab56cf3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
